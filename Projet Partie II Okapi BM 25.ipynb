{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 5 Okapi BM 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn,scipy,rank_bm25\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split as train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "from scipy import sparse\n",
    "from rank_bm25 import BM25Okapi,BM25L,BM25Plus\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "### Pour inverser le tableau afin de correspondre à la taille. \n",
    "def bm25_fit_transform(features,corpus):# Un corpus tokenisé\n",
    "    bm25 = BM25Okapi(corpus,k1=1.8,b=0.75)\n",
    "    tmp = []\n",
    "    for x in features:\n",
    "        tmp.append(bm25.get_scores([x]))\n",
    "    X = [[0 for x in range(len(features))] for y in range(len(tmp[0]))]\n",
    "    for i in range(len(tmp[0])):\n",
    "        for j in range(len(tmp)):\n",
    "            X[i][j]=tmp[j][i]\n",
    "    return np.asarray(X)\n",
    "\n",
    "\n",
    "class BM25(object):\n",
    "    def __init__(self, b=0.75, k1=1.6):\n",
    "        self.vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\" Fit IDF to documents X \"\"\"\n",
    "        self.vectorizer.fit(X)\n",
    "        y = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        self.avdl = y.sum(1).mean()\n",
    "\n",
    "    def transform(self, q, X):\n",
    "        \"\"\" Calculate BM25 between query q and documents X \"\"\"\n",
    "        b, k1, avdl = self.b, self.k1, self.avdl\n",
    "\n",
    "        # apply CountVectorizer\n",
    "        X = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        len_X = X.sum(1).A1\n",
    "        q, = super(TfidfVectorizer, self.vectorizer).transform([q])\n",
    "        assert sparse.isspmatrix_csr(q)\n",
    "\n",
    "        # convert to csc for better column slicing\n",
    "        X = X.tocsc()[:, q.indices]\n",
    "        denom = X + (k1 * (1 - b + b * len_X / avdl))[:, None]\n",
    "        # idf(t) = log [ n / df(t) ] + 1 in sklearn, so it need to be coneverted\n",
    "        # to idf(t) = log [ n / df(t) ] with minus 1\n",
    "        idf = self.vectorizer._tfidf.idf_[None, q.indices] - 1.\n",
    "        numer = X.multiply(np.broadcast_to(idf, X.shape)) * (k1 + 1)                                                          \n",
    "        return (numer / denom).sum(1).A1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouvrir les tweets et les tweets de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "1268\n",
      "1643\n",
      "494\n",
      "411\n",
      "123\n",
      "318\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def ouvrir(dossier):\n",
    "    données = []\n",
    "    g = os.walk(dossier)\n",
    "    for path,dir_list,file_list in g:  \n",
    "        for file_name in file_list:  \n",
    "            with open(os.path.join(path, file_name),'r',encoding=\"utf-8\") as f:\n",
    "                g1 = f.readline()\n",
    "                while g1!=\"\":\n",
    "                    données.append(g1.strip())\n",
    "                    g1 = f.readline()\n",
    "    return données\n",
    "\n",
    "mixed = ouvrir(\"mixed\")\n",
    "negatif = ouvrir(\"negative\")\n",
    "objectif = ouvrir(\"objective\")\n",
    "positif = ouvrir(\"positive\")\n",
    "\n",
    "print(len(mixed))\n",
    "print(len(negatif))\n",
    "print(len(objectif))\n",
    "print(len(positif))\n",
    "\n",
    "import json\n",
    "with open(\"task1-testGold.csv.json\",'r') as load_f:\n",
    "     load_dict = json.load(load_f)\n",
    "\n",
    "objectif_test = []\n",
    "pos_test = []\n",
    "neg_test = []\n",
    "for x in load_dict[\"objective\"]:\n",
    "    objectif_test.append(x['content'])\n",
    "for x in load_dict[\"positive\"]:\n",
    "    pos_test.append(x['content'])\n",
    "for x in load_dict[\"negative\"]:\n",
    "    neg_test.append(x['content'])\n",
    "    \n",
    "print(len(objectif_test))\n",
    "print(len(pos_test))\n",
    "print(len(neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement / BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "1268\n",
      "1643\n",
      "494\n",
      "123\n",
      "318\n",
      "411\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokeniser(l):\n",
    "    données = []\n",
    "    for x in l:\n",
    "        données.append(word_tokenize(x,language=\"french\"))\n",
    "    return données\n",
    "\n",
    "mixed_tokeniser = tokeniser(mixed)\n",
    "negatif_tokeniser = tokeniser(negatif)\n",
    "objectif_tokeniser = tokeniser(objectif)\n",
    "positif_tokeniser = tokeniser(positif)\n",
    "pos_test_tokeniser = tokeniser(pos_test)\n",
    "neg_test_tokeniser = tokeniser(neg_test)\n",
    "obj_test_tokeniser = tokeniser(objectif_test)\n",
    "\n",
    "    \n",
    "print(len(mixed_tokeniser))\n",
    "print(len(negatif_tokeniser))\n",
    "print(len(objectif_tokeniser))\n",
    "print(len(positif_tokeniser))\n",
    "print(len(pos_test_tokeniser))\n",
    "print(len(neg_test_tokeniser))\n",
    "print(len(obj_test_tokeniser))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraire des features pour l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13637\n"
     ]
    }
   ],
   "source": [
    "Corpus = positif+negatif+objectif+pos_test+neg_test+objectif_test\n",
    "Corpus_tokens = positif_tokeniser+negatif_tokeniser+objectif_tokeniser+pos_test_tokeniser+neg_test_tokeniser+obj_test_tokeniser\n",
    "\n",
    "TFIDF_Vect = TfidfVectorizer(encoding = \"utf-8\",lowercase = True,stop_words=stop_words_fr,norm=None, smooth_idf=False)\n",
    "X1 = TFIDF_Vect.fit_transform(Corpus)\n",
    "\n",
    "features = TFIDF_Vect.get_feature_names()\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation avec Okapi BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrôle\n",
      "4257\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25()\n",
    "bm25.fit(Corpus)\n",
    "print(features[3910])\n",
    "l = bm25.transform(features[3910],Corpus)\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13637\n"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "for x in features:\n",
    "    columns.append(bm25.transform(x,Corpus))\n",
    "print(len(columns))\n",
    "columns = np.asarray(columns)\n",
    "print(columns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4257, 13637)\n"
     ]
    }
   ],
   "source": [
    "X1 = [[0 for x in range(len(features))] for y in range(len(columns[0]))]\n",
    "for i in range(len(columns[0])):\n",
    "    for j in range(len(columns)):\n",
    "        X1[i][j]=columns[j][i]\n",
    "X1 = np.asarray(X1) \n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3405, 13637) (3405,)\n",
      "(852, 13637) (852,)\n"
     ]
    }
   ],
   "source": [
    "X1_train = X1[:len(positif+negatif+objectif)]\n",
    "X1_test = X1[len(positif+negatif+objectif):]\n",
    "Y1_train = np.asarray([\"positif\" for x in positif]+[\"negatif\" for x in negatif]+[\"objectif\" for x in objectif])\n",
    "Y1_test = np.asarray([\"positif\" for x in pos_test]+[\"negatif\" for x in neg_test]+[\"objectif\" for x in objectif_test])\n",
    "print(X1_train.shape,Y1_train.shape)\n",
    "print(X1_test.shape,Y1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### J48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT = DT.fit(X1_train,Y1_train)\n",
    "\n",
    "Okapi_BM25_DecisionTree = DT.score(X1_test,Y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cross-Validation avec J48 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Scores = cross_val_score(DT,X1,Y,cv = 10, scoring = 'accuracy')\n",
    "Okapi_BM25_DecisionTree_CV = Scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisation en arbre en PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(DT,out_file=None,\n",
    "                                feature_names=features,\n",
    "                                class_names=['positif','negatif','objectif'],\n",
    "                                filled=True,rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(\"Okapi BM 25 J48 Arbre.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zijian/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF = RF.fit(X1_train,Y1_train)\n",
    "\n",
    "Okapi_BM25_RandomForest = RF.score(X1_test,Y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation avec Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores = cross_val_score(RF,X1,Y,cv = 10, scoring = 'accuracy')\n",
    "Okapi_BM25_RandomForest_CV = Scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Montrer le résultat final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test final : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>J48</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test Final</th>\n",
       "      <td>0.66784</td>\n",
       "      <td>0.710094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross Validation</th>\n",
       "      <td>0.68383</td>\n",
       "      <td>0.722322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      J48  Random Forest\n",
       "Test Final        0.66784       0.710094\n",
       "Cross Validation  0.68383       0.722322"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Test final : \")\n",
    "pd.DataFrame({\"J48\":[Okapi_BM25_DecisionTree,Okapi_BM25_DecisionTree_CV],\"Random Forest\":[Okapi_BM25_RandomForest,Okapi_BM25_RandomForest_CV]},index = [\"Test Final\",\"Cross Validation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
